{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPl9fazcXnyWLa0f02H6+Zc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pegasus-nathanael/Test_Nathan/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKAvFoYjlJzM",
        "outputId": "8250e01b-6abe-4a0d-d321-19116e77ba76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-contrib-python) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision\n",
        "!pip install opencv-contrib-python\n",
        "!pip install scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "from torch.nn import Module\n",
        "from torch.nn import Conv2d\n",
        "from torch.nn import Linear\n",
        "from torch.nn import MaxPool2d\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import LogSoftmax\n",
        "from torch import flatten"
      ],
      "metadata": {
        "id": "mgQTC6BUoAII"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(Module):\n",
        "\tdef __init__(self, numChannels, classes):\n",
        "\t\t# call the parent constructor\n",
        "\t\tsuper(LeNet, self).__init__()\n",
        "\t\t# initialize first set of CONV => RELU => POOL layers\n",
        "\t\tself.conv1 = Conv2d(in_channels=numChannels, out_channels=20,\n",
        "\t\t\tkernel_size=(5, 5))\n",
        "\t\tself.relu1 = ReLU()\n",
        "\t\tself.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "\t\t# initialize second set of CONV => RELU => POOL layers\n",
        "\t\tself.conv2 = Conv2d(in_channels=20, out_channels=50,\n",
        "\t\t\tkernel_size=(5, 5))\n",
        "\t\tself.relu2 = ReLU()\n",
        "\t\tself.maxpool2 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "\t\t# initialize first (and only) set of FC => RELU layers\n",
        "\t\tself.fc1 = Linear(in_features=800, out_features=500)\n",
        "\t\tself.relu3 = ReLU()\n",
        "\t\t# initialize our softmax classifier\n",
        "\t\tself.fc2 = Linear(in_features=500, out_features=classes)\n",
        "\t\tself.logSoftmax = LogSoftmax(dim=1)\n",
        "\n",
        "\t# Define the forward method within the LeNet class\n",
        "\tdef forward(self, x):\n",
        "\t\t# pass the input through our first set of CONV => RELU =>\n",
        "\t\t# POOL layers\n",
        "\t\tx = self.conv1(x)\n",
        "\t\tx = self.relu1(x)\n",
        "\t\tx = self.maxpool1(x)\n",
        "\t\t# pass the output from the previous layer through the second\n",
        "\t\t# set of CONV => RELU => POOL layers\n",
        "\t\tx = self.conv2(x)\n",
        "\t\tx = self.relu2(x)\n",
        "\t\tx = self.maxpool2(x)\n",
        "\t\t# flatten the output from the previous layer and pass it\n",
        "\t\t# through our only set of FC => RELU layers\n",
        "\t\tx = flatten(x, 1)\n",
        "\t\tx = self.fc1(x)\n",
        "\t\tx = self.relu3(x)\n",
        "\t\t# pass the output to our softmax classifier to get our output\n",
        "\t\t# predictions\n",
        "\t\tx = self.fc2(x)\n",
        "\t\toutput = self.logSoftmax(x)\n",
        "\t\t# return the output predictions\n",
        "\t\treturn output"
      ],
      "metadata": {
        "id": "8u3WnRvfoFIG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "# import the necessary packages\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.datasets import KMNIST\n",
        "from torch.optim import Adam\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import torch\n",
        "import time"
      ],
      "metadata": {
        "id": "HDaWqTCJn5bw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = {'model': '/content/mon_modele.pth', 'plot': '/content/ma_figure.png'}"
      ],
      "metadata": {
        "id": "K61juyu2oiki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define training hyperparameters\n",
        "INIT_LR = 1e-3\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "# define the train and val splits\n",
        "TRAIN_SPLIT = 0.75\n",
        "VAL_SPLIT = 1 - TRAIN_SPLIT\n",
        "# set the device we will be using to train the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "S_Zy3eC49ufY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the KMNIST dataset\n",
        "print(\"[INFO] loading the KMNIST dataset...\")\n",
        "trainData = KMNIST(root=\"data\", train=True, download=True,\n",
        "\ttransform=ToTensor())\n",
        "testData = KMNIST(root=\"data\", train=False, download=True,\n",
        "\ttransform=ToTensor())\n",
        "# calculate the train/validation split\n",
        "print(\"[INFO] generating the train/validation split...\")\n",
        "numTrainSamples = int(len(trainData) * TRAIN_SPLIT)\n",
        "numValSamples = int(len(trainData) * VAL_SPLIT)\n",
        "(trainData, valData) = random_split(trainData,\n",
        "\t[numTrainSamples, numValSamples],\n",
        "\tgenerator=torch.Generator().manual_seed(42))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4RxTCJm-J02",
        "outputId": "3d525847-6303-493c-e920-9549dc5b274f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading the KMNIST dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 18.2M/18.2M [00:05<00:00, 3.03MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 276kB/s]\n",
            "100%|██████████| 3.04M/3.04M [00:02<00:00, 1.30MB/s]\n",
            "100%|██████████| 5.12k/5.12k [00:00<00:00, 8.87MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] generating the train/validation split...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import DataLoader from torch.utils.data\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "5coK1T0FBRlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the train, validation, and test data loaders\n",
        "trainDataLoader = DataLoader(trainData, shuffle=True,\n",
        "\tbatch_size=BATCH_SIZE)\n",
        "valDataLoader = DataLoader(valData, batch_size=BATCH_SIZE)\n",
        "testDataLoader = DataLoader(testData, batch_size=BATCH_SIZE)\n",
        "# calculate steps per epoch for training and validation set\n",
        "trainSteps = len(trainDataLoader.dataset) // BATCH_SIZE\n",
        "valSteps = len(valDataLoader.dataset) // BATCH_SIZE"
      ],
      "metadata": {
        "id": "L_A2hYRS_EXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the LeNet model\n",
        "print(\"[INFO] initializing the LeNet model...\")\n",
        "model = LeNet(\n",
        "\tnumChannels=1,\n",
        "\tclasses=len(trainData.dataset.classes)).to(device)\n",
        "# initialize our optimizer and loss function\n",
        "opt = Adam(model.parameters(), lr=INIT_LR)\n",
        "lossFn = nn.NLLLoss()\n",
        "# initialize a dictionary to store training history\n",
        "H = {\n",
        "\t\"train_loss\": [],\n",
        "\t\"train_acc\": [],\n",
        "\t\"val_loss\": [],\n",
        "\t\"val_acc\": []\n",
        "}\n",
        "# measure how long training is going to take\n",
        "print(\"[INFO] training the network...\")\n",
        "startTime = time.time()"
      ],
      "metadata": {
        "id": "2zYTZcMK_2BI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loop over our epochs\n",
        "for e in range(0, EPOCHS):\n",
        "    # set the model in training mode\n",
        "    print(f\"[INFO] epochs {e+1} / {EPOCHS}\")\n",
        "\n",
        "    model.train()\n",
        "    # initialize the total training and validation loss\n",
        "    totalTrainLoss = 0\n",
        "    totalValLoss = 0\n",
        "    # initialize the number of correct predictions in the training\n",
        "    # and validation step\n",
        "    trainCorrect = 0\n",
        "    valCorrect = 0\n",
        "    # loop over the training set\n",
        "    for (x, y) in trainDataLoader:\n",
        "        # send the input to the device\n",
        "        (x, y) = (x.to(device), y.to(device))\n",
        "        # perform a forward pass and calculate the training loss\n",
        "        pred = model(x)\n",
        "        loss = lossFn(pred, y)\n",
        "        # zero out the gradients, perform the backpropagation step,\n",
        "        # and update the weights\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        # add the loss to the total training loss so far and\n",
        "        # calculate the number of correct predictions\n",
        "        totalTrainLoss += loss\n",
        "        trainCorrect += (pred.argmax(1) == y).type(\n",
        "            torch.float).sum().item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P31NJRL8AE7N",
        "outputId": "ff682750-3b06-419a-eafc-9fe2b6e5bb71"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] epochs 1 / 10\n",
            "[INFO] epochs 2 / 10\n",
            "[INFO] epochs 3 / 10\n",
            "[INFO] epochs 4 / 10\n",
            "[INFO] epochs 5 / 10\n",
            "[INFO] epochs 6 / 10\n",
            "[INFO] epochs 7 / 10\n",
            "[INFO] epochs 8 / 10\n",
            "[INFO] epochs 9 / 10\n",
            "[INFO] epochs 10 / 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# switch off autograd for evaluation\n",
        "with torch.no_grad():\n",
        "\t\t# set the model in evaluation mode\n",
        "\t\tmodel.eval()\n",
        "\t\t# loop over the validation set\n",
        "\t\tfor (x, y) in valDataLoader:\n",
        "\t\t\t# send the input to the device\n",
        "\t\t\t(x, y) = (x.to(device), y.to(device))\n",
        "\t\t\t# make the predictions and calculate the validation loss\n",
        "\t\t\tpred = model(x)\n",
        "\t\t\ttotalValLoss += lossFn(pred, y)\n",
        "\t\t\t# calculate the number of correct predictions\n",
        "\t\t\tvalCorrect += (pred.argmax(1) == y).type(\n",
        "\t\t\t\ttorch.float).sum().item()"
      ],
      "metadata": {
        "id": "XGnX0DP7AQmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the average training and validation loss\n",
        "avgTrainLoss = totalTrainLoss / trainSteps\n",
        "avgValLoss = totalValLoss / valSteps\n",
        "# calculate the training and validation accuracy\n",
        "trainCorrect = trainCorrect / len(trainDataLoader.dataset)\n",
        "valCorrect = valCorrect / len(valDataLoader.dataset)\n",
        "# update our training history\n",
        "H[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
        "H[\"train_acc\"].append(trainCorrect)\n",
        "H[\"val_loss\"].append(avgValLoss.cpu().detach().numpy())\n",
        "H[\"val_acc\"].append(valCorrect)\n",
        "# print the model training and validation information\n",
        "print(\"[INFO] EPOCH: {}/{}\".format(e + 1, EPOCHS))\n",
        "print(\"Train loss: {:.6f}, Train accuracy: {:.4f}\".format(avgTrainLoss, trainCorrect))\n",
        "print(\"Val loss: {:.6f}, Val accuracy: {:.4f}\\n\".format(avgValLoss, valCorrect))"
      ],
      "metadata": {
        "id": "FSrTPJqSESxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finish measuring how long training took\n",
        "endTime = time.time()\n",
        "print(\"[INFO] total time taken to train the model: {:.2f}s\".format(\n",
        "\tendTime - startTime))\n",
        "# we can now evaluate the network on the test set\n",
        "print(\"[INFO] evaluating network...\")\n",
        "# turn off autograd for testing evaluation\n",
        "with torch.no_grad():\n",
        "\t# set the model in evaluation mode\n",
        "\tmodel.eval()\n",
        "\n",
        "\t# initialize a list to store our predictions\n",
        "\tpreds = []\n",
        "\t# loop over the test set\n",
        "\tfor (x, y) in testDataLoader:\n",
        "\t\t# send the input to the device\n",
        "\t\tx = x.to(device)\n",
        "\t\t# make the predictions and add them to the list\n",
        "\t\tpred = model(x)\n",
        "\t\tpreds.extend(pred.argmax(axis=1).cpu().numpy())\n",
        "# generate a classification report\n",
        "print(classification_report(testData.targets.cpu().numpy(),\n",
        "\tnp.array(preds), target_names=testData.classes))"
      ],
      "metadata": {
        "id": "LhGeoTmfE1TT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the training loss and accuracy\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(H[\"train_loss\"], label=\"train_loss\")\n",
        "plt.plot(H[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(H[\"train_acc\"], label=\"train_acc\")\n",
        "plt.plot(H[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(args[\"plot\"])\n",
        "# serialize the model to disk\n",
        "torch.save(model, args[\"model\"])"
      ],
      "metadata": {
        "id": "-dG59q6oE2KV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accéder au chemin d'accès du modèle\n",
        "model_path = args['model']  # '/content/mon_modele.pth'\n",
        "\n",
        "# Accéder au chemin d'accès du graphique\n",
        "plot_path = args['plot']  # '/content/ma_figure.png'\n",
        "\n",
        "# Utiliser les chemins d'accès pour charger le modèle ou afficher le graphique\n",
        "# par exemple :\n",
        "# Load the model with weights_only=False\n",
        "loaded_model = torch.load(model_path, weights_only=False)  # Charger le modèle\n",
        "\n",
        "# Ou pour afficher le graphique avec matplotlib :\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "img = mpimg.imread(plot_path)\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aS6NydLNRvdb"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}